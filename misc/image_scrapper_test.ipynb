{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\r\n",
    "import pandas as pd\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import time\r\n",
    "import io\r\n",
    "from PIL import Image\r\n",
    "import hashlib\r\n",
    "\r\n",
    "# download wikipage\r\n",
    "#wikipage = \"https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_continent_(data_file)\"\r\n",
    "#result = requests.get(wikipage)\r\n",
    "\r\n",
    "# if successful parse the download into a BeautifulSoup object, which allows easy manipulation \r\n",
    "#if result.status_code == 200:\r\n",
    "#    soup = BeautifulSoup(result.content, \"html.parser\")\r\n",
    "    \r\n",
    "# find the object with HTML class wikitable sortable\r\n",
    "#table = soup.find('table',{'class':'wikitable sortable'})\r\n",
    "\r\n",
    "# loop through all the rows and pull the text\r\n",
    "#new_table = []\r\n",
    "#for row in table.find_all('tr')[1:]:\r\n",
    "#    column_marker = 0\r\n",
    "#    columns = row.find_all('td')\r\n",
    "#    new_table.append([column.get_text() for column in columns])\r\n",
    "    \r\n",
    "#df = pd.DataFrame(new_table, columns=['ContinentCode','Alpha2','Alpha3','PhoneCode','Name'])\r\n",
    "#df['Name'] = df['Name'].str.replace('\\n','')\r\n",
    "#df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import selenium\r\n",
    "from selenium import webdriver\r\n",
    "# This is the path I use\r\n",
    "# DRIVER_PATH = '.../Desktop/Scraping/chromedriver 2'\r\n",
    "# Put the path for your ChromeDriver here\r\n",
    "DRIVER_PATH = 'C:/Users/alexa/Documents/GitHub/anic0077.github.io/misc/chromedriver'\r\n",
    "wd = webdriver.Chrome(executable_path=DRIVER_PATH)\r\n",
    "wd.quit()\r\n",
    "#wd.get('https://google.com')\r\n",
    "#search_box = wd.find_element_by_css_selector('input.gLFyf')\r\n",
    "#search_box.send_keys('Dogs')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#wd.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def fetch_image_urls(query:str, max_links_to_fetch:int, wd:webdriver, sleep_between_interactions:float=0.5):\r\n",
    "    def scroll_to_end(wd):\r\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\r\n",
    "        time.sleep(sleep_between_interactions)    \r\n",
    "    \r\n",
    "    # build the google query\r\n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\r\n",
    "\r\n",
    "    # load the page\r\n",
    "    wd.get(search_url.format(q=query))\r\n",
    "\r\n",
    "    image_urls = set()\r\n",
    "    image_count = 0\r\n",
    "    results_start = 0\r\n",
    "    while image_count < max_links_to_fetch:\r\n",
    "        scroll_to_end(wd)\r\n",
    "\r\n",
    "        # get all image thumbnail results\r\n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\r\n",
    "        number_results = len(thumbnail_results)\r\n",
    "        \r\n",
    "        print(f\"Found: {number_results} search results. Extracting links from {results_start}:{number_results}\")\r\n",
    "        \r\n",
    "        for img in thumbnail_results[results_start:number_results]:\r\n",
    "            # try to click every thumbnail such that we can get the real image behind it\r\n",
    "            try:\r\n",
    "                img.click()\r\n",
    "                time.sleep(sleep_between_interactions)\r\n",
    "            except Exception:\r\n",
    "                continue\r\n",
    "\r\n",
    "            # extract image urls    \r\n",
    "            actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\r\n",
    "            for actual_image in actual_images:\r\n",
    "                if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):\r\n",
    "                    image_urls.add(actual_image.get_attribute('src'))\r\n",
    "\r\n",
    "            image_count = len(image_urls)\r\n",
    "\r\n",
    "            if len(image_urls) >= max_links_to_fetch:\r\n",
    "                print(f\"Found: {len(image_urls)} image links, done!\")\r\n",
    "                break\r\n",
    "        else:\r\n",
    "            print(\"Found:\", len(image_urls), \"image links, looking for more ...\")\r\n",
    "            time.sleep(1)\r\n",
    "            #return\r\n",
    "            load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\r\n",
    "            if load_more_button:\r\n",
    "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\r\n",
    "\r\n",
    "        # move the result startpoint further down\r\n",
    "        results_start = len(thumbnail_results)\r\n",
    "\r\n",
    "    return image_urls"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def persist_image(folder_path:str,url:str):\r\n",
    "    try:\r\n",
    "        image_content = requests.get(url).content\r\n",
    "\r\n",
    "    except Exception as e:\r\n",
    "        print(f\"ERROR - Could not download {url} - {e}\")\r\n",
    "\r\n",
    "    try:\r\n",
    "        image_file = io.BytesIO(image_content)\r\n",
    "        image = Image.open(image_file).convert('RGB')\r\n",
    "        file_path = os.path.join(folder_path,hashlib.sha1(image_content).hexdigest()[:10] + '.jpg')\r\n",
    "        with open(file_path, 'wb') as f:\r\n",
    "            image.save(f, \"JPEG\", quality=85)\r\n",
    "        print(f\"SUCCESS - saved {url} - as {file_path}\")\r\n",
    "    except Exception as e:\r\n",
    "        print(f\"ERROR - Could not save {url} - {e}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#combining above 2 functions\r\n",
    "def search_and_download(search_term:str,driver_path:str,number_images:int,target_path='./images'):\r\n",
    "    target_folder = os.path.join(target_path,'_'.join(search_term.lower().split(' ')))\r\n",
    "\r\n",
    "    if not os.path.exists(target_folder):\r\n",
    "        os.makedirs(target_folder)\r\n",
    "\r\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\r\n",
    "        res = fetch_image_urls(search_term, number_images, wd=wd, sleep_between_interactions=0.5)\r\n",
    "        \r\n",
    "    for elem in res:\r\n",
    "        persist_image(target_folder,elem)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "search_term = 'lavender'\r\n",
    "\r\n",
    "search_and_download(\r\n",
    "    search_term = search_term,\r\n",
    "    driver_path = DRIVER_PATH,\r\n",
    "    number_images = 500\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found: 100 search results. Extracting links from 0:100\n",
      "Found: 161 image links, looking for more ...\n",
      "Found: 212 search results. Extracting links from 100:212\n",
      "Found: 338 image links, looking for more ...\n",
      "Found: 312 search results. Extracting links from 212:312\n",
      "Found: 492 image links, looking for more ...\n",
      "Found: 412 search results. Extracting links from 312:412\n",
      "Found: 501 image links, done!\n",
      "ERROR - Could not save https://1v1d1e1lmiki1lgcvx32p49h8fe-wpengine.netdna-ssl.com/wp-content/uploads/2019/09/1568352085-inifiniti-car-getty-960x540.jpg - cannot identify image file <_io.BytesIO object at 0x000002D120196130>\n",
      "SUCCESS - saved https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRZ6FPRLnSKFPTmkbJ5XLg-kxf5XSk-JEc4-A&usqp=CAU - as ./images\\car\\7a31359504.jpg\n",
      "SUCCESS - saved https://www.kia.com/content/dam/kwcms/au/en/images/category/7-seater-family-suv-kia-sorento.jpg - as ./images\\car\\df6bd6a9c7.jpg\n",
      "SUCCESS - saved https://static01.nyt.com/images/2021/03/26/business/25wheels/00CARS-COMBO-superJumbo.jpg - as ./images\\car\\ebf739cee8.jpg\n",
      "SUCCESS - saved https://www.motortrend.com/uploads/sites/5/2019/12/MotorTrend-Most-Important-Cars-of-the-Decade.jpg?fit=around%7C875:492 - as ./images\\car\\33158e033c.jpg\n",
      "SUCCESS - saved https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQjl9oanSBFm9Ks9hR6T-K7qO-2CrKnnFQBvQ&usqp=CAU - as ./images\\car\\2ded41af3a.jpg\n",
      "SUCCESS - saved https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRjLxyu_-f2w0nroiOvA1mZzc_29RuSaY6kJg&usqp=CAU - as ./images\\car\\5c4c624203.jpg\n",
      "SUCCESS - saved https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ2mQsLqPh-N75P-o8s2NjVWrFMMkCQMiwsLQ&usqp=CAU - as ./images\\car\\9791ec4410.jpg\n",
      "SUCCESS - saved https://carsguide-res.cloudinary.com/image/upload/f_auto,fl_lossy,q_auto,t_cg_hero_large/v1/editorial/How-many-cars-in-the-world-advice-1001x565p.jpg - as ./images\\car\\a05b070da7.jpg\n",
      "SUCCESS - saved https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTQO95ZecuZZf65c9ooFDdiNvJ9iZmoGSn5Gg&usqp=CAU - as ./images\\car\\3d56eafd25.jpg\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "268ef592ca12fc1c2bffff621c6f69b2d3cbaf29b6122947478221211c9fca52"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}